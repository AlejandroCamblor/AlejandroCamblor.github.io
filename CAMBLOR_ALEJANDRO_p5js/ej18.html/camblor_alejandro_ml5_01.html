<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ML5 01 · Cámara + Detección</title>

  <!-- ml5.js (versión fija para evitar cambios de API) -->
  <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>

  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 16px; }
    #wrap { position: relative; width: min(720px, 100%); }
    video, canvas { width: 100%; height: auto; border-radius: 10px; }
    canvas { position: absolute; left: 0; top: 0; }
    button { padding: 10px 12px; font-size: 14px; cursor: pointer; }
    .row { display:flex; gap:12px; flex-wrap: wrap; align-items:center; margin-bottom: 10px; }
    .badge { display:inline-block; border:1px solid #ccc; border-radius:999px; padding: 3px 10px; }
  </style>
</head>

<body>
  <h1>ML5 01 · Cámara en móvil + detección</h1>

  <div class="row">
    <button id="btnStart">Iniciar cámara</button>
    <span id="status" class="badge">Estado: esperando…</span>
    <span id="best" class="badge">Mejor detección: —</span>
  </div>

  <div id="wrap">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
  </div>

  <div>
   <h3> Explicación de cómo funciona el código</h3>

   <p>
       Este código básicamente te permite usar la cámara de tu móvil u ordenador para detectar objetos en tiempo real.
       Lo hace gracias a una herramienta llamada ml5.js, que facilita la integración de inteligencia artificial en
       páginas web. El código utiliza un modelo que puede reconocer una gran variedad de cosas, como personas, animales, coches, etc. 
       <br> Cuando haces clic en el botón "Iniciar cámara", el navegador te pide permiso para usar la cámara. Una vez que le das permiso, empieza a mostrar lo que ve la cámara en una ventana.
       Además, sobre esa ventana se coloca un lienzo (canvas) donde se dibujan los resultados de la detección de
       objetos. A medida que el video de la cámara va avanzando, el modelo de inteligencia artificial analiza cada
       cuadro para ver qué objetos hay en la imagen. 
       <br> Cuando detecta algo, dibuja un rectángulo alrededor del objeto en el lienzo y pone una etiqueta con el nombre del objeto y el porcentaje de certeza de que lo ha identificado
       correctamente. Además, siempre muestra cuál es el objeto que tiene la mayor posibilidad de haber sido correctamente identificado. 
       <br> Este proceso se repite constantemente: el sistema detecta objetos en cada cuadro de video y los muestra en la pantalla en tiempo real. Así, puedes ver cómo el sistema va
       identificando objetos a medida que se muestran frente a la cámara. 
       <br> En resumen, lo que hace este código es permitir que tu navegador use la cámara para reconocer objetos a través de inteligencia artificial, todo en tiempo real.
   </p>

  </div>


  <script>
    const btnStart = document.getElementById("btnStart");
    const statusEl = document.getElementById("status");
    const bestEl = document.getElementById("best");

    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    let detector = null;
    let running = false;

    function setStatus(t) { statusEl.textContent = "Estado: " + t; }

    async function initCamera() {
      // En móvil, "environment" intenta usar la cámara trasera
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: "environment" } },
        audio: false
      });

      video.srcObject = stream;

      await new Promise(res => video.onloadedmetadata = () => res());

      // Ajustar canvas al tamaño real del vídeo
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    function draw(detections) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 3;
      ctx.font = "16px system-ui, Arial";

      for (const d of detections) {
        ctx.strokeRect(d.x, d.y, d.width, d.height);
        const label = `${d.label} (${Math.round(d.confidence * 100)}%)`;
        ctx.fillText(label, d.x + 6, Math.max(16, d.y + 16));
      }
    }

    function pickBest(detections) {
      if (!detections || detections.length === 0) return null;
      let best = detections[0];
      for (const d of detections) {
        if (d.confidence > best.confidence) best = d;
      }
      return best;
    }

    function loopDetect() {
      if (!running || !detector) return;

      detector.detect(video, (err, results) => {
        if (err) {
          console.error(err);
          setStatus("error en detección (ver consola)");
          running = false;
          return;
        }

        draw(results);

        const best = pickBest(results);
        bestEl.textContent = best
          ? `Mejor detección: ${best.label} (${Math.round(best.confidence * 100)}%)`
          : "Mejor detección: —";

        requestAnimationFrame(loopDetect);
      });
    }

    btnStart.addEventListener("click", async () => {
      try {
        btnStart.disabled = true;

        setStatus("iniciando cámara…");
        await initCamera();

        setStatus("cargando modelo COCO-SSD…");
        detector = await ml5.objectDetector("cocossd");

        setStatus("detectando…");
        running = true;
        loopDetect();

      } catch (e) {
        console.error(e);
        setStatus(`error: ${e.name} — ${e.message}`);
        btnStart.disabled = false;
      }
    });
  </script>
</body>
</html>