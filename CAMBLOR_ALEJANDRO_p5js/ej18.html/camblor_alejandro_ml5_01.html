<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ML5 01 · Cámara + Detección</title>

  <!-- ml5.js (versión fija para evitar cambios de API) -->
  <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>

  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 16px; }
    #wrap { position: relative; width: min(720px, 100%); }
    video, canvas { width: 100%; height: auto; border-radius: 10px; }
    canvas { position: absolute; left: 0; top: 0; }
    button { padding: 10px 12px; font-size: 14px; cursor: pointer; }
    .row { display:flex; gap:12px; flex-wrap: wrap; align-items:center; margin-bottom: 10px; }
    .badge { display:inline-block; border:1px solid #ccc; border-radius:999px; padding: 3px 10px; }
  </style>
</head>

<body>
  <h1>ML5 01 · Cámara en móvil + detección</h1>

  <div class="row">
    <button id="btnStart">Iniciar cámara</button>
    <span id="status" class="badge">Estado: esperando…</span>
    <span id="best" class="badge">Mejor detección: —</span>
  </div>

  <div id="wrap">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
  </div>

  <div>
   <h3> Explicación de cómo funciona el código</h3>
    <h4> setStatus(t) </h4>
      <p>
       Esta función cambia el texto que se muestra en el elemento con el id status. Es utilizada para actualizar el estado del sistema, como "iniciando cámara", "cargando modelo", o "detectando objetos".
      </p>
    <h4> initCamera() </h4>
      <p>
       Esta función se encarga de acceder a la cámara del dispositivo. Usa navigator.mediaDevices.getUserMedia() para grabar y luego lo muestra en la etiqueta "video" de la página.
      </p>
    <h4> draw(detections) </h4>
      <p>
       Esta función es responsable de dibujar lo detectado anteriormente en el canvas. Para cada objeto detectado, dibuja un rectángulo alrededor y escribe su etiqueta (nombre, lo que supuestamente es) junto con el porcentaje de probabilidad de que este haya sido correctamente identificado.
      </p>
    <h4> pickBest(detections) </h4>
      <p>
       Esta función selecciona la detección con la mayor certeza. Si se han detectado varios objetos, escoge el objeto con la mayor probabilidad de ser identificado correctamente.
      </p>
    <h4> loopDetect() </h4>
      <p>
       Esta función es la que controla la detección en tiempo real. Se ejecuta en un bucle continuo, donde llama al modelo de detección de objetos y actualiza la pantalla con las detecciones y el estado.
      </p>
    <h4> btnStart.addEventListener() </h4>
      <p>
       Este bloque de código configura el comportamiento del botón "Iniciar cámara". Cuando el usuario hace clic en el botón, se ejecuta un conjunto de acciones:
      <br> Deshabilita el botón para evitar múltiples clics.
      <br> Muestra un mensaje de estado que indica que la cámara está siendo iniciada.
      <br> Llama a initCamera() para configurar la cámara.
      <br> Carga el modelo de detección COCO-SSD.
      <br> Comienza el proceso de detección en tiempo real al activar el bucle loopDetect().
      </p>

  </div>


  <script>
    const btnStart = document.getElementById("btnStart");
    const statusEl = document.getElementById("status");
    const bestEl = document.getElementById("best");

    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    let detector = null;
    let running = false;

    function setStatus(t) { statusEl.textContent = "Estado: " + t; }

    async function initCamera() {
      // En móvil, "environment" intenta usar la cámara trasera
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { ideal: "environment" } },
        audio: false
      });

      video.srcObject = stream;

      await new Promise(res => video.onloadedmetadata = () => res());

      // Ajustar canvas al tamaño real del vídeo
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    function draw(detections) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 3;
      ctx.font = "16px system-ui, Arial";

      for (const d of detections) {
        ctx.strokeRect(d.x, d.y, d.width, d.height);
        const label = `${d.label} (${Math.round(d.confidence * 100)}%)`;
        ctx.fillText(label, d.x + 6, Math.max(16, d.y + 16));
      }
    }

    function pickBest(detections) {
      if (!detections || detections.length === 0) return null;
      let best = detections[0];
      for (const d of detections) {
        if (d.confidence > best.confidence) best = d;
      }
      return best;
    }

    function loopDetect() {
      if (!running || !detector) return;

      detector.detect(video, (err, results) => {
        if (err) {
          console.error(err);
          setStatus("error en detección (ver consola)");
          running = false;
          return;
        }

        draw(results);

        const best = pickBest(results);
        bestEl.textContent = best
          ? `Mejor detección: ${best.label} (${Math.round(best.confidence * 100)}%)`
          : "Mejor detección: —";

        requestAnimationFrame(loopDetect);
      });
    }

    btnStart.addEventListener("click", async () => {
      try {
        btnStart.disabled = true;

        setStatus("iniciando cámara…");
        await initCamera();

        setStatus("cargando modelo COCO-SSD…");
        detector = await ml5.objectDetector("cocossd");

        setStatus("detectando…");
        running = true;
        loopDetect();

      } catch (e) {
        console.error(e);
        setStatus(`error: ${e.name} — ${e.message}`);
        btnStart.disabled = false;
      }
    });
  </script>
</body>

</html>

